

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Boosting to Uniformity &mdash; hep_ml 0.2.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/my_style.css" type="text/css" />
  

  

  
    <link rel="top" title="hep_ml 0.2.0 documentation" href="../index.html"/>
        <link rel="up" title="Code examples" href="notebooks.html"/>
        <link rel="prev" title="Boosting to Uniformity" href="BoostingToUniformity.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-nav-search">
        

        
          <a href="../index.html" class="icon icon-home"> hep_ml
        

        
        </a>

        
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

        
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        
          
          
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../gb.html">Gradient boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../losses.html">Losses for Gradient Boosting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../losses.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../uboost.html">uBoost</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../uboost.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../metrics.html">Metric functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../metrics.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nnet.html">Neural networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../nnet.html#examples">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nnet.html#loss-functions">Loss functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nnet.html#trainers">Trainers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../reweight.html">Reweighting algorithms</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="notebooks.html">Code examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="BoostingToUniformity.html">Boosting to Uniformity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="BoostingToUniformity.html#distribution-of-events-in-different-files-in-the-dalitz-features">Distribution of events in different files in the Dalitz features</a></li>
<li class="toctree-l3"><a class="reference internal" href="BoostingToUniformity.html#preparation-of-train-test-datasets">Preparation of train/test datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="BoostingToUniformity.html#setting-up-classifiers-training">Setting up classifiers, training</a></li>
<li class="toctree-l3"><a class="reference internal" href="BoostingToUniformity.html#lets-look-at-the-results-of-training">Lets look at the results of training</a></li>
<li class="toctree-l3"><a class="reference internal" href="BoostingToUniformity.html#sde-squared-deviation-of-efficiency-learning-curve">SDE (squared deviation of efficiency) learning curve</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="BoostingToUniformity.html#roc-curves-after-training">ROC curves after training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="BoostingToUniformity.html#signal-efficiency">Signal efficiency</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="">Boosting to Uniformity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#loading-data">Loading data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#distribution-of-events-in-different-files-in-the-dalitz-features">Distribution of events in different files in the Dalitz features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preparation-of-train-test-datasets">Preparation of train/test datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="#setting-up-classifiers-training">Setting up classifiers, training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#lets-look-at-the-results-of-training">Lets look at the results of training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sde-squared-deviation-of-efficiency-learning-curve">SDE (squared deviation of efficiency) learning curve</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cvm-learning-curve">CvM learning curve</a></li>
<li class="toctree-l3"><a class="reference internal" href="#roc-curves-after-training">ROC curves after training</a></li>
<li class="toctree-l3"><a class="reference internal" href="#signal-efficiency">Signal efficiency</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">hep_ml</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
          <li><a href="notebooks.html">Code examples</a> &raquo;</li>
      
    <li>Boosting to Uniformity</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/notebooks/BoostingToUniformity2.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document">
            
  <div class="section" id="boosting-to-uniformity">
<h1>Boosting to Uniformity<a class="headerlink" href="#boosting-to-uniformity" title="Permalink to this headline">¶</a></h1>
<p>In physical applications frequently we need to achieve uniformity of
predictions along some features. For instance, when testing the
existence of new particle, we need classifier to be uniform in
background along the mass (otherwise one can get false discovery due to
peaking background).</p>
<p>This notebook contains some comparison of classifiers. The target is to
obtain flat effiency in <strong>signal</strong> (without significally loosing quality
of classification) in Dalitz features.</p>
<p>The classifiers compared are * plain <strong>GradientBoosting</strong> * <strong>uBoost</strong>
* gradient boosting with knn-Ada loss (<strong>UGB+knnAda</strong>) * gradient
boosting with FlatnessLoss (<strong>UGB+FlatnessLoss</strong>)</p>
<p>We use dataset from paper about <code class="docutils literal"><span class="pre">uBoost</span></code> for demonstration purposes.
We have plenty of data here, so results are quite stable</p>
<div class="code python highlight-python"><div class="highlight"><pre># downloading data
!wget -O ../data/dalitzdata.root -nc https://github.com/arogozhnikov/hep_ml/blob/data/data/dalitzdata.root?raw=true
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>Файл «../data/dalitzdata.root» уже существует; не загружается.
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre>%pylab inline
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>Populating the interactive namespace from numpy and matplotlib
</pre></div>
</div>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">pandas</span><span class="o">,</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="c"># this wrapper makes it possible to train on subset of features</span>
<span class="kn">from</span> <span class="nn">rep.estimators</span> <span class="kn">import</span> <span class="n">SklearnClassifier</span>

<span class="kn">from</span> <span class="nn">hep_ml.commonutils</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">hep_ml</span> <span class="kn">import</span> <span class="n">uboost</span><span class="p">,</span> <span class="n">gradientboosting</span> <span class="k">as</span> <span class="n">ugb</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
</div>
<div class="section" id="loading-data">
<h2>Loading data<a class="headerlink" href="#loading-data" title="Permalink to this headline">¶</a></h2>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">root_numpy</span>
<span class="n">used_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;Y1&quot;</span><span class="p">,</span> <span class="s">&quot;Y2&quot;</span><span class="p">,</span> <span class="s">&quot;Y3&quot;</span><span class="p">,</span> <span class="s">&quot;M2AB&quot;</span><span class="p">,</span> <span class="s">&quot;M2AC&quot;</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">root_numpy</span><span class="o">.</span><span class="n">root2array</span><span class="p">(</span><span class="s">&#39;../data/dalitzdata.root&#39;</span><span class="p">,</span> <span class="n">treename</span><span class="o">=</span><span class="s">&#39;tree&#39;</span><span class="p">))</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">&#39;labels&#39;</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">&#39;labels&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="distribution-of-events-in-different-files-in-the-dalitz-features">
<h2>Distribution of events in different files in the Dalitz features<a class="headerlink" href="#distribution-of-events-in-different-files-in-the-dalitz-features" title="Permalink to this headline">¶</a></h2>
<p>As we can see, the background is distributed mostly in the corners of
Dalitz plot, and for traditional classifiers this results in poor
effieciency of signal in the corners.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">plot_distribution</span><span class="p">(</span><span class="n">data_frame</span><span class="p">,</span> <span class="n">var_name1</span><span class="o">=</span><span class="s">&#39;M2AB&#39;</span><span class="p">,</span> <span class="n">var_name2</span><span class="o">=</span><span class="s">&#39;M2AC&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The function to plot 2D distribution histograms&quot;&quot;&quot;</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">hist2d</span><span class="p">(</span><span class="n">data_frame</span><span class="p">[</span><span class="n">var_name1</span><span class="p">],</span> <span class="n">data_frame</span><span class="p">[</span><span class="n">var_name2</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">40</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">var_name1</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">var_name2</span><span class="p">)</span>
    <span class="n">pylab</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>

<span class="n">pylab</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">pylab</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;signal&quot;</span><span class="p">),</span>       <span class="n">plot_distribution</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">labels</span><span class="o">==</span><span class="mi">1</span><span class="p">])</span>
<span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">pylab</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&quot;background&quot;</span><span class="p">),</span>   <span class="n">plot_distribution</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">labels</span><span class="o">==</span><span class="mi">0</span><span class="p">])</span>
<span class="k">pass</span>
</pre></div>
</div>
<img alt="../_images/BoostingToUniformity_7_0.png" src="../_images/BoostingToUniformity_7_0.png" />
</div>
<div class="section" id="preparation-of-train-test-datasets">
<h2>Preparation of train/test datasets<a class="headerlink" href="#preparation-of-train-test-datasets" title="Permalink to this headline">¶</a></h2>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">trainX</span><span class="p">,</span> <span class="n">testX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">testY</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="setting-up-classifiers-training">
<h2>Setting up classifiers, training<a class="headerlink" href="#setting-up-classifiers-training" title="Permalink to this headline">¶</a></h2>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">uniform_features</span>  <span class="o">=</span> <span class="p">[</span><span class="s">&quot;M2AB&quot;</span><span class="p">,</span> <span class="s">&quot;M2AC&quot;</span><span class="p">]</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;Y1&quot;</span><span class="p">,</span> <span class="s">&quot;Y2&quot;</span><span class="p">,</span> <span class="s">&quot;Y3&quot;</span><span class="p">]</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">base_estimator</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>uBoost</strong> training takes much time, so we reduce number of
efficiency_steps, use prediction smoothing and run uBoost in threads</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">rep.metaml</span> <span class="kn">import</span> <span class="n">ClassifiersFactory</span>

<span class="n">classifiers</span> <span class="o">=</span> <span class="n">ClassifiersFactory</span><span class="p">()</span>

<span class="n">base_ada</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">classifiers</span><span class="p">[</span><span class="s">&#39;AdaBoost&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">base_ada</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">train_features</span><span class="p">)</span>


<span class="n">knnloss</span> <span class="o">=</span> <span class="n">ugb</span><span class="o">.</span><span class="n">KnnAdaLossFunction</span><span class="p">(</span><span class="n">uniform_features</span><span class="p">,</span> <span class="n">knn</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">uniform_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ugbKnn</span> <span class="o">=</span> <span class="n">ugb</span><span class="o">.</span><span class="n">UGradientBoostingClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">knnloss</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
                                        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">train_features</span><span class="o">=</span><span class="n">train_features</span><span class="p">)</span>
<span class="n">classifiers</span><span class="p">[</span><span class="s">&#39;uGB+knnAda&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">ugbKnn</span><span class="p">)</span>

<span class="n">uboost_clf</span> <span class="o">=</span> <span class="n">uboost</span><span class="o">.</span><span class="n">uBoostClassifier</span><span class="p">(</span><span class="n">uniform_features</span><span class="o">=</span><span class="n">uniform_features</span><span class="p">,</span> <span class="n">uniform_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                     <span class="n">base_estimator</span><span class="o">=</span><span class="n">base_estimator</span><span class="p">,</span>
                                     <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span> <span class="n">train_features</span><span class="o">=</span><span class="n">train_features</span><span class="p">,</span>
                                     <span class="n">efficiency_steps</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">classifiers</span><span class="p">[</span><span class="s">&#39;uBoost&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">uboost_clf</span><span class="p">)</span>

<span class="n">flatnessloss</span> <span class="o">=</span> <span class="n">ugb</span><span class="o">.</span><span class="n">KnnFlatnessLossFunction</span><span class="p">(</span><span class="n">uniform_features</span><span class="p">,</span> <span class="n">fl_coefficient</span><span class="o">=</span><span class="mf">3.</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mf">1.3</span><span class="p">,</span> <span class="n">uniform_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ugbFL</span> <span class="o">=</span> <span class="n">ugb</span><span class="o">.</span><span class="n">UGradientBoostingClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">flatnessloss</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                       <span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
                                       <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">train_features</span><span class="o">=</span><span class="n">train_features</span><span class="p">)</span>
<span class="n">classifiers</span><span class="p">[</span><span class="s">&#39;uGB+FL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">ugbFL</span><span class="p">)</span>


<span class="n">classifiers</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">parallel_profile</span><span class="o">=</span><span class="s">&#39;threads-4&#39;</span><span class="p">)</span>
<span class="k">pass</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>model AdaBoost     was trained in 86.50 seconds
model uGB+knnAda   was trained in 156.14 seconds
model uBoost       was trained in 443.68 seconds
model uGB+FL       was trained in 308.80 seconds
Totally spent 443.68 seconds on training
</pre></div>
</div>
</div>
<div class="section" id="lets-look-at-the-results-of-training">
<h2>Lets look at the results of training<a class="headerlink" href="#lets-look-at-the-results-of-training" title="Permalink to this headline">¶</a></h2>
<p>dependence of quality on the number of trees built (ROC AUC - area under
the ROC curve, the more the better)</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">rep.report.metrics</span> <span class="kn">import</span> <span class="n">RocAuc</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">classifiers</span><span class="o">.</span><span class="n">test_on</span><span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testY</span><span class="p">)</span>

<span class="n">ylim</span><span class="p">(</span><span class="mf">0.88</span><span class="p">,</span> <span class="mf">0.94</span><span class="p">)</span>
<span class="n">report</span><span class="o">.</span><span class="n">learning_curve</span><span class="p">(</span><span class="n">RocAuc</span><span class="p">(),</span> <span class="n">steps</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/BoostingToUniformity_15_1.png" src="../_images/BoostingToUniformity_15_1.png" />
</div>
<div class="section" id="sde-squared-deviation-of-efficiency-learning-curve">
<h2>SDE (squared deviation of efficiency) learning curve<a class="headerlink" href="#sde-squared-deviation-of-efficiency-learning-curve" title="Permalink to this headline">¶</a></h2>
<p>SDE vs the number of built trees. SDE is memtric of nonuniformity - less
is better.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">hep_ml.metrics</span> <span class="kn">import</span> <span class="n">BinBasedSDE</span><span class="p">,</span> <span class="n">KnnBasedCvM</span>
<span class="n">report</span><span class="o">.</span><span class="n">learning_curve</span><span class="p">(</span><span class="n">BinBasedSDE</span><span class="p">(</span><span class="n">uniform_features</span><span class="p">,</span> <span class="n">uniform_label</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/BoostingToUniformity_17_1.png" src="../_images/BoostingToUniformity_17_1.png" />
</div>
<div class="section" id="cvm-learning-curve">
<h2>CvM learning curve<a class="headerlink" href="#cvm-learning-curve" title="Permalink to this headline">¶</a></h2>
<p>CvM is metric of non-uniformity based on Cramer-von Mises distance. We
are using Knn version now.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">report</span><span class="o">.</span><span class="n">learning_curve</span><span class="p">(</span><span class="n">KnnBasedCvM</span><span class="p">(</span><span class="n">uniform_features</span><span class="p">,</span> <span class="n">uniform_label</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/BoostingToUniformity_19_1.png" src="../_images/BoostingToUniformity_19_1.png" />
</div>
<div class="section" id="roc-curves-after-training">
<h2>ROC curves after training<a class="headerlink" href="#roc-curves-after-training" title="Permalink to this headline">¶</a></h2>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">report</span><span class="o">.</span><span class="n">roc</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_plot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/BoostingToUniformity_21_0.png" src="../_images/BoostingToUniformity_21_0.png" />
</div>
<div class="section" id="signal-efficiency">
<h2>Signal efficiency<a class="headerlink" href="#signal-efficiency" title="Permalink to this headline">¶</a></h2>
<p>global cut corresponds to average signal efficiency=0.5. In ideal case
the picture shall be white.</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">report</span><span class="o">.</span><span class="n">efficiencies_2d</span><span class="p">(</span><span class="n">uniform_features</span><span class="p">,</span> <span class="n">efficiency</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">signal_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                       <span class="n">labels_dict</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">&#39;signal&#39;</span><span class="p">})</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre>/Users/axelr/venvs/rep_env/lib/python2.7/site-packages/matplotlib/axes/_axes.py:475: UserWarning: No labelled objects found. Use label=&#39;...&#39; kwarg on individual plots.
  warnings.warn(&quot;No labelled objects found. &quot;
</pre></div>
</div>
<img alt="../_images/BoostingToUniformity_23_2.png" src="../_images/BoostingToUniformity_23_2.png" />
<p>the same for global efficiency = 0.7</p>
<div class="code python highlight-python"><div class="highlight"><pre><span class="n">report</span><span class="o">.</span><span class="n">efficiencies_2d</span><span class="p">(</span><span class="n">uniform_features</span><span class="p">,</span> <span class="n">efficiency</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">signal_label</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_bins</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                       <span class="n">labels_dict</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">&#39;signal&#39;</span><span class="p">})</span>
</pre></div>
</div>
<img alt="../_images/BoostingToUniformity_25_1.png" src="../_images/BoostingToUniformity_25_1.png" />
</div>
</div>


          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="BoostingToUniformity.html" class="btn btn-neutral" title="Boosting to Uniformity" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, Yandex; Alex Rogozhnikov and contributors.
    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>